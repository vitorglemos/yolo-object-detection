{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"\"\n",
    "file_name_target = \"obj.names\"\n",
    "labels_path = os.path.sep.join([file_path, file_name_target])\n",
    "labels = open(labels_path).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.sep.join([file_path, \"yolov3_model_v1.weights\"])\n",
    "config_path = os.path.sep.join([file_path, \"yolov3_model_v1.cfg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 0x7f3ee5076550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 220, 225],\n",
       "       [ 95, 179,  61],\n",
       "       [234, 203,  92],\n",
       "       [  3,  98, 243],\n",
       "       [ 14, 149, 245],\n",
       "       [ 46, 106, 244],\n",
       "       [ 99, 187,  71],\n",
       "       [212, 153, 199],\n",
       "       [188, 174,  65],\n",
       "       [153,  20,  44],\n",
       "       [203, 152, 102],\n",
       "       [214, 240,  39],\n",
       "       [121,  24,  34],\n",
       "       [114, 210,  65],\n",
       "       [239,  39, 214],\n",
       "       [244, 151,  25],\n",
       "       [ 74, 145, 222],\n",
       "       [ 14, 202,  85],\n",
       "       [145, 117,  87],\n",
       "       [184, 189, 221],\n",
       "       [116, 237, 109]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "ln = net.getLayerNames() \n",
    "\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16, 10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_image(image, neural_layer, neural_model):\n",
    "    start_time = time.time()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (self.image_width, self.image_height),\n",
    "                                     swapRB=True, crop=False)\n",
    "    neural_model.setInput(blob)\n",
    "    neural_layer_outputs = neural_model.forward(neural_layer)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_detection = float('{:.3f}'.format(end_time - start_time))\n",
    "    return self.neural_model, image, neural_layer_outputs, time_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_img(detection, _confidence, boxes, confidence, classes_index, verbose=True):\n",
    "    scores = detection[5:]     \n",
    "    classe_index_ = np.argmax(scores)  \n",
    "    confidence = scores[classe_index_]\n",
    "\n",
    "    if confidence > _confidence:\n",
    "\n",
    "        if verbose:\n",
    "            print(f\" scores: {str(scores)} \\n classes: {labels[classeID]} \\n confid.: {confidence}\")\n",
    "\n",
    "        boxes = detection[0:4] * np.array([W, H, W, H])\n",
    "      \n",
    "        (centerX, centerY, width, height) = boxes.astype(\"int\")\n",
    "\n",
    "        x = int(centerX - (width / 2))\n",
    "        y = int(centerY - (height / 2))\n",
    "\n",
    "        boxes.append([x, y, int(width), int(height)])\n",
    "        confidence.append(float(confianca))\n",
    "        classes_index.append(classeID)\n",
    "      \n",
    "    return boxes, confidence, classes_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_boxes_draw(image, index, confidence, boxes, colors, labels):\n",
    "    (x, y) = (boxes[index][0], boxes[index][1])\n",
    "    (w, h) = (boxes[index][2], boxes[index][3])\n",
    "\n",
    "    color_ = [int(c) for c in colors[classes_index[index]]]\n",
    "\n",
    "    cv2.rectangle(imagem, (x, y), (x + w, y + h), color_, 2) \n",
    "\n",
    "    text = \"{}: {:.3f}\".format(labels[classes_index[index]], confidences[index])\n",
    " \n",
    "    labelSize = cv2.getTextSize(texto,cv2.FONT_HERSHEY_COMPLEX,0.5, 2)\n",
    "    txl = labelSize\n",
    "    top = max(y, t[0][1])\n",
    "    cv2.rectangle(imagem, (x, y - round(1.5 * txl[0][1])), (x + round(1 * txl[0][0]), y), color_, cv2.FILLED)\n",
    "    cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    return image, x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_threshold = 0.6\n",
    "_threshold_NMS = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, image, layer_outputs = blob_imagem(net, image)\n",
    "\n",
    "boxes = list()\n",
    "confidences = list()\n",
    "classes_index = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in layer_outputs:\n",
    "    for detection in output:\n",
    "        boxes, confidences, classes_index = detection_img(detection, _threshold, \n",
    "                                                          boxes, confidences, classes_index)\n",
    "\n",
    "objs = cv2.dnn.NMSBoxes(boxes, confidences, _threshold, _threshold_NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detect objects: \" + str(len(objs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(objs) > 0:\n",
    "    for index in objs.flatten():\n",
    "        image, x, y, w, h = image_boxes_draw(image, index, confidences, \n",
    "                                             boxes, colors, labels, verbose=False)\n",
    "        object_image = imagem_cp[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "show_image(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
